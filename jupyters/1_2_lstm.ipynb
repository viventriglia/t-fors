{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ebd374",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\" # \"jax\"\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\"\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\".50\"\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    confusion_matrix\n",
    ")\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, LSTM, Dense, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from var import DATA_OUT, IMAGE_OUT, FORECAST_HOURS_IN_ADVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132cda7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(Path(DATA_OUT, 'df_dataset.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a36726e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = df[\n",
    "    [\n",
    "        'ie_fix',\n",
    "        'ie_mav_6h',\n",
    "        'iu_fix',\n",
    "        'iu_mav_6h',\n",
    "        'hf',\n",
    "        'hf_mav_2h',\n",
    "        'f_107_adj',\n",
    "        'hp_30',\n",
    "        'smr',\n",
    "        'solar_zenith_angle',\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "y = df[f'tid_within_{FORECAST_HOURS_IN_ADVANCE}h'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ce6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.loc['2014':'2015'].fillna(0).copy()\n",
    "y_train = y.loc['2014':'2015'].copy()\n",
    "\n",
    "X_test = X.loc['2016'].fillna(0).copy()\n",
    "y_test = y.loc['2016'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07875b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = 20\n",
    "T = 2 * 24 * n_days\n",
    "\n",
    "X_train_lstm, y_train_lstm = [], []\n",
    "\n",
    "for i in range(y_train.shape[0] - (T-1)):\n",
    "    X_train_lstm.append(X_train.iloc[i: i+T].values)\n",
    "    y_train_lstm.append(y_train.iloc[i + (T-1)])\n",
    "\n",
    "X_train_lstm, y_train_lstm = np.array(X_train_lstm), np.array(y_train_lstm).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b53237",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train data dimensions: {X_train_lstm.shape}, {y_train_lstm.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea442195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to use a T-days window of input data for predicting target class\n",
    "# It means I need to prepend (T-1) last train records to the 1st test window\n",
    "\n",
    "prepend_features = X_train.iloc[-(T-1):]\n",
    "X_test = pd.concat([prepend_features, X_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e3bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lstm, y_test_lstm = [], []\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    X_test_lstm.append(X_test.iloc[i: i+T].values)\n",
    "    y_test_lstm.append(y_test.iloc[i])\n",
    "\n",
    "X_test_lstm, y_test_lstm = np.array(X_test_lstm), np.array(y_test_lstm).reshape(-1,1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf00f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test data dimensions: {X_test_lstm.shape}, {y_test_lstm.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c99533",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS = [64, 32, 1]                 # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_lstm.shape[0]      # number of training examples (2D)\n",
    "M_TEST = X_test_lstm.shape[0]        # number of test examples (2D), full=X_test.shape[0]\n",
    "N = X_train_lstm.shape[2]            # number of features\n",
    "BATCH = 320                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80929e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    LSTM(\n",
    "        input_shape=(T, N),\n",
    "        units=LAYERS[0],\n",
    "        activation='tanh',\n",
    "        recurrent_activation='hard_sigmoid',\n",
    "        # kernel_regularizer=l2(LAMBD),\n",
    "        # recurrent_regularizer=l2(LAMBD),\n",
    "        dropout=DP,\n",
    "        recurrent_dropout=RDP,\n",
    "        return_sequences=True,\n",
    "        return_state=False,\n",
    "        stateful=False,\n",
    "        unroll=False\n",
    "        )\n",
    ")\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(\n",
    "    LSTM(\n",
    "        units=LAYERS[1],\n",
    "        activation='tanh',\n",
    "        recurrent_activation='hard_sigmoid',\n",
    "        # kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "        dropout=DP,\n",
    "        recurrent_dropout=RDP,\n",
    "        return_sequences=False,\n",
    "        return_state=False,\n",
    "        stateful=False,\n",
    "        unroll=False\n",
    "        )\n",
    ")\n",
    "\n",
    "model.add(\n",
    "    Dense(units=LAYERS[2], activation='sigmoid')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89de08b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    "    optimizer=Adam(learning_rate=LR)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba98c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8857347",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train_lstm,\n",
    "    y_train_lstm,\n",
    "    epochs=EPOCH,\n",
    "    batch_size=BATCH,\n",
    "    validation_split=0.0,\n",
    "    validation_data=(X_test_lstm[:M_TEST], y_test_lstm[:M_TEST]),\n",
    "    shuffle=True,\n",
    "    verbose='auto',\n",
    "    #callbacks=[lr_decay, early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2948c42f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
