{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ebd374",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, LSTM, Dense, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from var import DATA_OUT, IMAGE_OUT, FORECAST_HOURS_IN_ADVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132cda7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(Path(DATA_OUT, 'df_dataset.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a36726e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = df[\n",
    "    [\n",
    "        'ie_fix',\n",
    "        'ie_mav_6h',\n",
    "        'iu_fix',\n",
    "        'iu_mav_6h',\n",
    "        'hf',\n",
    "        'f_107_adj',\n",
    "        'hp_30',\n",
    "        'smr',\n",
    "        'solar_zenith_angle',\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "y = df[f'tid_within_{FORECAST_HOURS_IN_ADVANCE}h'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ce6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.loc['2018':'2020'].copy()\n",
    "y_train = y.loc['2018':'2020'].copy()\n",
    "\n",
    "X_test = X.loc['2021':'2022'].copy()\n",
    "y_test = y.loc['2021':'2022'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8723566",
   "metadata": {},
   "source": [
    "## Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be13f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_features = [\n",
    "    'ie_fix',\n",
    "    'ie_mav_6h',\n",
    "    'iu_fix',\n",
    "    'iu_mav_6h',\n",
    "    'f_107_adj',\n",
    "    'smr',\n",
    "]\n",
    "\n",
    "minmax_features = [\n",
    "    'hf',\n",
    "    'hp_30',\n",
    "    'solar_zenith_angle',\n",
    "]\n",
    "\n",
    "standard_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "minmax_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', MinMaxScaler(feature_range=(0,1)))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('standard', standard_transformer, standard_features),\n",
    "        ('minmax', minmax_transformer, minmax_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessing = Pipeline(\n",
    "    steps=[('preprocessor', preprocessor)]\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "preprocessing.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3490cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pp, X_test_pp = preprocessing.transform(X_train), preprocessing.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a208c4",
   "metadata": {},
   "source": [
    "## Data transformation for LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56589511",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = 20\n",
    "T = 2 * 24 * n_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07875b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lstm, y_train_lstm = [], []\n",
    "\n",
    "for i in range(y_train.shape[0] - (T-1)):\n",
    "    X_train_lstm.append(X_train_pp[i: i+T])\n",
    "    y_train_lstm.append(y_train.iloc[i + (T-1)])\n",
    "\n",
    "X_train_lstm, y_train_lstm = np.array(X_train_lstm), np.array(y_train_lstm).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b53237",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train data dimensions: {X_train_lstm.shape}, {y_train_lstm.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea442195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to use a T-days window of input data for predicting target class\n",
    "# It means I need to prepend (T-1) last train records to the 1st test window\n",
    "\n",
    "prepend_features = X_train[-(T-1):]\n",
    "X_test = pd.concat([prepend_features, X_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e3bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lstm, y_test_lstm = [], []\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    X_test_lstm.append(X_test[i: i+T])\n",
    "    y_test_lstm.append(y_test.iloc[i])\n",
    "\n",
    "X_test_lstm, y_test_lstm = np.array(X_test_lstm), np.array(y_test_lstm).reshape(-1,1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf00f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test data dimensions: {X_test_lstm.shape}, {y_test_lstm.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d098208",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c99533",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS = [32, 16, 1]                 # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_lstm.shape[0]      # number of training examples (2D)\n",
    "M_TEST = X_test_lstm.shape[0]        # number of test examples (2D)\n",
    "N = X_train_lstm.shape[2]            # number of features\n",
    "BATCH = 320                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.1                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80929e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Input(shape=(T, N))\n",
    ")\n",
    "\n",
    "model.add(\n",
    "    LSTM(\n",
    "        units=LAYERS[0],\n",
    "        activation='tanh',\n",
    "        recurrent_activation='hard_sigmoid',\n",
    "        kernel_regularizer=l2(LAMBD),\n",
    "        recurrent_regularizer=l2(LAMBD),\n",
    "        dropout=DP,\n",
    "        recurrent_dropout=RDP,\n",
    "        return_sequences=True,\n",
    "        return_state=False,\n",
    "        stateful=False,\n",
    "        )\n",
    ")\n",
    "\n",
    "# model.add(BatchNormalization())\n",
    "# \n",
    "# model.add(\n",
    "#     LSTM(\n",
    "#         units=LAYERS[1],\n",
    "#         activation='tanh',\n",
    "#         recurrent_activation='hard_sigmoid',\n",
    "#         kernel_regularizer=l2(LAMBD),\n",
    "#         recurrent_regularizer=l2(LAMBD),\n",
    "#         dropout=DP,\n",
    "#         recurrent_dropout=RDP,\n",
    "#         return_sequences=True,\n",
    "#         return_state=False,\n",
    "#         stateful=False,\n",
    "#         )\n",
    "# )\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(\n",
    "    LSTM(\n",
    "        units=LAYERS[1],\n",
    "        activation='tanh',\n",
    "        recurrent_activation='hard_sigmoid',\n",
    "        kernel_regularizer=l2(LAMBD),\n",
    "        recurrent_regularizer=l2(LAMBD),\n",
    "        dropout=DP,\n",
    "        recurrent_dropout=RDP,\n",
    "        return_sequences=False,\n",
    "        return_state=False,\n",
    "        stateful=False,\n",
    "        )\n",
    ")\n",
    "\n",
    "model.add(\n",
    "    Dense(units=LAYERS[2], activation='sigmoid')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89de08b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['f1_score'],\n",
    "    optimizer=Adam(learning_rate=LR)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba98c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8bb550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate decay\n",
    "lr_decay = ReduceLROnPlateau(\n",
    "    monitor='f1_score',\n",
    "    mode='max',\n",
    "    patience=1,\n",
    "    verbose=1, \n",
    "    factor=0.2,\n",
    "    min_lr=1e-5,\n",
    ")\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='f1_score',\n",
    "    min_delta=0, \n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode='max',\n",
    "    baseline=0,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c65da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8857347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = model.fit(\n",
    "    X_train_lstm,\n",
    "    y_train_lstm,\n",
    "    epochs=EPOCH,\n",
    "    batch_size=BATCH,\n",
    "    # validation_split=1/7,\n",
    "    validation_data=(X_test_lstm, y_test_lstm),\n",
    "    shuffle=False,\n",
    "    verbose='auto',\n",
    "    callbacks=[lr_decay, early_stop],\n",
    "    # class_weight=dict(enumerate(weights)),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
