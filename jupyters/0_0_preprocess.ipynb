{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fdc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "from var import DATA_IN, DATA_OUT, START_DATE, END_DATE, FORECAST_HOURS_IN_ADVANCE\n",
    "from src.io import read_time_series\n",
    "from src.preprocess import (\n",
    "    resample_time_series,\n",
    "    get_categories,\n",
    "    get_solar_position,\n",
    "    preprocess_ionosonde_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae9430",
   "metadata": {},
   "source": [
    "## TIDs catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d03e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tid = read_time_series(\n",
    "    Path(DATA_IN, 'TID_catalog.csv'),\n",
    "    column_names=[\n",
    "        'duration',\n",
    "        'period',\n",
    "        'amplitude',\n",
    "        'spectral_contribution',\n",
    "        'velocity',\n",
    "        'azimuth',\n",
    "        'quality_index',\n",
    "        'datetime',\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45db2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tid_30 = resample_time_series(df_tid, aggregation_function='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e823a8d1",
   "metadata": {},
   "source": [
    "Given the duration of a TID event, we repeat the information describing it for as long as it lasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d949f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tid_30['total_periods'] = (df_tid_30['duration'] * 60 / 30).round()\n",
    "\n",
    "df_tid_30_ = pd.DataFrame()\n",
    "for _, row in df_tid_30.dropna().reset_index().iterrows():\n",
    "    periods = int(row['total_periods'])\n",
    "    datetimes = pd.date_range(start=row['datetime'], periods=periods, freq='30T')\n",
    "    df_tid_30_ = pd.concat(\n",
    "        [df_tid_30_, pd.DataFrame({'datetime': datetimes, **row[1:]})],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    \n",
    "df_tid_30_ = df_tid_30_.set_index('datetime').drop(columns='total_periods')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb92528c",
   "metadata": {},
   "source": [
    "## Ionosonde Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259465e",
   "metadata": {},
   "source": [
    "### Athens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a0b16b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_athens_30 = preprocess_ionosonde_data(\n",
    "    station_name='AT138',\n",
    "    aggregation_function={\n",
    "        'spectral_contribution': 'median',\n",
    "        'velocity': 'median',\n",
    "        'azimuth': 'median',\n",
    "        'local_warning_level': 'max',\n",
    "    },\n",
    ").loc[START_DATE:END_DATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28acc670",
   "metadata": {},
   "source": [
    "### Fairford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1def11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairford_30 = preprocess_ionosonde_data(\n",
    "    station_name='FF051',\n",
    "    aggregation_function={\n",
    "        'spectral_contribution': 'median',\n",
    "        'velocity': 'median',\n",
    "        'azimuth': 'median',\n",
    "        'local_warning_level': 'max',\n",
    "    },\n",
    ").loc[START_DATE:END_DATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb62d45",
   "metadata": {},
   "source": [
    "### Juliusruh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f302b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_juliusruh_30 = preprocess_ionosonde_data(\n",
    "    station_name='JR055',\n",
    "    aggregation_function={\n",
    "        'spectral_contribution': 'median',\n",
    "        'velocity': 'median',\n",
    "        'azimuth': 'median',\n",
    "        'local_warning_level': 'max',\n",
    "    },\n",
    ").loc[START_DATE:END_DATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf3df53",
   "metadata": {},
   "source": [
    "### Průhonice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f3d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pruhonice_30 = preprocess_ionosonde_data(\n",
    "    station_name='PQ052',\n",
    "    aggregation_function={\n",
    "        'spectral_contribution': 'median',\n",
    "        'velocity': 'median',\n",
    "        'azimuth': 'median',\n",
    "        'local_warning_level': 'max',\n",
    "    },\n",
    ").loc[START_DATE:END_DATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17b23a5",
   "metadata": {},
   "source": [
    "### Rome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b26cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rome_30 = preprocess_ionosonde_data(\n",
    "    station_name='RO041',\n",
    "    aggregation_function={\n",
    "        'spectral_contribution': 'median',\n",
    "        'velocity': 'median',\n",
    "        'azimuth': 'median',\n",
    "        'local_warning_level': 'max',\n",
    "    },\n",
    ").loc[START_DATE:END_DATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564e760",
   "metadata": {},
   "source": [
    "### San Vito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a9972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_svito_30 = preprocess_ionosonde_data(\n",
    "    station_name='VT139',\n",
    "    aggregation_function={\n",
    "        'spectral_contribution': 'median',\n",
    "        'velocity': 'median',\n",
    "        'azimuth': 'median',\n",
    "        'local_warning_level': 'max',\n",
    "    },\n",
    ").loc[START_DATE:END_DATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c83c2b",
   "metadata": {},
   "source": [
    "### Merge all ionosondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7497cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ionosondes_30 = df_athens_30.merge(\n",
    "    df_fairford_30,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left',\n",
    ").merge(\n",
    "    df_juliusruh_30,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left',\n",
    ").merge(\n",
    "    df_pruhonice_30,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left',\n",
    ").merge(\n",
    "    df_rome_30,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left',\n",
    ").merge(\n",
    "    df_svito_30,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217f154",
   "metadata": {},
   "source": [
    "## L1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008415d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l1 = read_time_series(\n",
    "    Path(DATA_IN, 'SolarWind_Projected_Merged.csv'),\n",
    "    column_names=['datetime','bz','vx','rho'],\n",
    "    usecols=[0,6,8,11],\n",
    ").loc[START_DATE:END_DATE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdd5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l1_30 = resample_time_series(df_l1, aggregation_function='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51329546",
   "metadata": {},
   "source": [
    "## Newell (coupling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bab7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newell = read_time_series(\n",
    "    Path(DATA_IN, 'newell.csv'),\n",
    "    column_names=['datetime','newell'],\n",
    ").loc[START_DATE:END_DATE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da2f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newell_30 = resample_time_series(df_newell, aggregation_function='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86226a28",
   "metadata": {},
   "source": [
    "## HF-EU index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hf = read_time_series(\n",
    "    Path(DATA_IN, 'HF_EU_IDX.csv'),\n",
    "    column_names=['datetime','hf'],\n",
    ").loc[START_DATE:END_DATE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6802083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hf_30 = resample_time_series(df_hf, aggregation_function='mean')\n",
    "df_hf_30['hf'] = df_hf_30['hf'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6b047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n. of periods needed to get 2 hours\n",
    "periods = [2 * per_ for per_ in [2]]\n",
    "\n",
    "for per_ in periods:\n",
    "    # moving average\n",
    "    df_hf_30[f'hf_mav_{per_/2:.0f}h'] = df_hf_30['hf'].rolling(\n",
    "        window=int(per_)\n",
    "    ).mean().round(1)\n",
    "    \n",
    "df_hf_30 = df_hf_30.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa7392",
   "metadata": {},
   "source": [
    "## SMR (SuperMAG partial ring current index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe274ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smr = read_time_series(\n",
    "    Path(DATA_IN, 'SMR.csv'),\n",
    "    column_names=['datetime','smr'],\n",
    ").loc[START_DATE:END_DATE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab32d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smr_30 = resample_time_series(df_smr, aggregation_function='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0d19c4",
   "metadata": {},
   "source": [
    "## HP-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f1153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hp = read_time_series(\n",
    "    Path(DATA_IN, 'Hp30_ap30_IDX.csv'),\n",
    "    column_names=['hp_30','datetime'],\n",
    "    usecols=[0, 2]\n",
    ").loc[START_DATE:END_DATE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5896fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hp_30 = resample_time_series(df_hp, aggregation_function='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea5cb25",
   "metadata": {},
   "source": [
    "## Solar Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87f3476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar = read_time_series(\n",
    "    Path(DATA_IN, 'solar_data.csv'),\n",
    "    column_names=[\n",
    "        'day_of_rotation',\n",
    "        'n_sunsposts',\n",
    "        'f_107_adj',\n",
    "        'date',\n",
    "    ],\n",
    "    datetime_format=\"%d-%b-%Y\"\n",
    ").loc[START_DATE:END_DATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fa6153",
   "metadata": {},
   "source": [
    "## $\\frac{\\mathrm{d}B}{\\mathrm{d}t}$ (from magnetometers, divided into 5 latitude zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcdf51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Here, 55 means from 55° to 60°, and so on\n",
    "# latitude_zones = ['55', '60', '65', '70', '75']\n",
    "# dfs_mm, dfs_mm_30 = dict(), dict()\n",
    "\n",
    "# # Read, resample and take first difference\n",
    "# for latitude_ in latitude_zones:\n",
    "#     dfs_mm[latitude_] = read_time_series(\n",
    "#         Path(DATA_IN, f'MM{latitude_}.csv'),\n",
    "#         column_names=['datetime', f'h_{latitude_}'],\n",
    "#     ).loc[START_DATE:END_DATE]\n",
    "    \n",
    "#     dfs_mm_30[latitude_] = resample_time_series(dfs_mm[latitude_], aggregation_function='median')\n",
    "#     dfs_mm_30[latitude_][f'h_{latitude_}_diff'] = dfs_mm_30[latitude_][f'h_{latitude_}'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4062b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge all the data\n",
    "# df_mm_30 = dfs_mm_30[latitude_zones[0]].copy()\n",
    "\n",
    "# for latitude_ in latitude_zones[1:]:\n",
    "#     df_mm_30 = df_mm_30.merge(\n",
    "#         dfs_mm_30[latitude_][f'h_{latitude_}_diff'],\n",
    "#         left_index=True,\n",
    "#         right_index=True,\n",
    "#     )\n",
    "\n",
    "# df_mm_30 = df_mm_30.drop(columns='h_55')\n",
    "\n",
    "# # Delete dfs because are heavy objects\n",
    "# del dfs_mm, dfs_mm_30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c685a",
   "metadata": {},
   "source": [
    "## Auroral Electrojet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e350e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ejet = read_time_series(\n",
    "    Path(DATA_IN, 'ImageIDX.csv'),\n",
    "    column_names=['il','iu','ie','datetime'],\n",
    ").loc[START_DATE:END_DATE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5402da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ejet_30 = resample_time_series(df_ejet, aggregation_function='median')\n",
    "df_ejet_30['ie'] = df_ejet_30['ie'].round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa9837e",
   "metadata": {},
   "source": [
    "We detected **anomalous IE values**\n",
    "\n",
    "The reported values appear to be affected by instrumental **offsets** that have a time window of 1 or more consecutive days\n",
    "\n",
    "We removed the offset by subtracting a value equal to the average of the jumps before and after the affected day(s) (```ill_dates```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9d8d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ejet_30['ie_diff'] = df_ejet_30['ie'].diff()\n",
    "\n",
    "ill_dates = [\n",
    "    ['2015-05-31', '2015-06-01'],\n",
    "    ['2015-11-27', '2015-12-01'],\n",
    "    ['2015-12-04', '2015-12-07'],\n",
    "    ['2018-08-29', '2018-08-31'],\n",
    "    ['2018-09-01', '2018-09-08'],\n",
    "    ['2019-12-27', '2020-01-01'],\n",
    "]\n",
    "\n",
    "df_ejet_30['ie_fix'] = df_ejet_30['ie']\n",
    "for range_ in ill_dates:\n",
    "    offset_ = np.round(\n",
    "        (\n",
    "            df_ejet_30.loc[range_[0], 'ie_diff'].values[0] -\n",
    "            df_ejet_30.loc[range_[-1], 'ie_diff'].values[0]\n",
    "        ) / 2,\n",
    "        1\n",
    "    )\n",
    "    \n",
    "    df_ejet_30.loc[\n",
    "        range_[0]: pd.to_datetime(range_[1]) - pd.Timedelta(minutes=30),\n",
    "        'ie_fix',\n",
    "    ] -= offset_\n",
    "    \n",
    "df_ejet_30['ie_fix'] = df_ejet_30['ie_fix'].clip(lower=0)\n",
    "df_ejet_30 = df_ejet_30.drop(columns='ie_diff')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25726f5b",
   "metadata": {},
   "source": [
    "Similarly for IU and IL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23204c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ejet_30['iu_diff'] = df_ejet_30['iu'].diff()\n",
    "\n",
    "ill_dates = [\n",
    "    ['2015-05-31', '2015-06-01'],\n",
    "    ['2015-11-27', '2015-12-01'],\n",
    "    ['2015-12-04', '2015-12-07'],\n",
    "    ['2019-12-27', '2020-01-01'],\n",
    "]\n",
    "\n",
    "df_ejet_30['iu_fix'] = df_ejet_30['iu']\n",
    "for range_ in ill_dates:\n",
    "    offset_ = np.round(\n",
    "        (\n",
    "            df_ejet_30.loc[range_[0], 'iu_diff'].values[0] -\n",
    "            df_ejet_30.loc[range_[-1], 'iu_diff'].values[0]\n",
    "        ) / 2,\n",
    "        1\n",
    "    )\n",
    "    \n",
    "    df_ejet_30.loc[\n",
    "        range_[0]: pd.to_datetime(range_[1]) - pd.Timedelta(minutes=30),\n",
    "        'iu_fix',\n",
    "    ] -= offset_\n",
    "    \n",
    "df_ejet_30 = df_ejet_30.drop(columns='iu_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b1ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ejet_30['il_diff'] = df_ejet_30['il'].diff()\n",
    "\n",
    "ill_dates = [\n",
    "    ['2018-08-29', '2018-08-31'],\n",
    "    ['2018-09-01', '2018-09-08'],\n",
    "]\n",
    "\n",
    "df_ejet_30['il_fix'] = df_ejet_30['il']\n",
    "for range_ in ill_dates:\n",
    "    offset_ = np.round(\n",
    "        (\n",
    "            df_ejet_30.loc[range_[0], 'il_diff'].values[0] -\n",
    "            df_ejet_30.loc[range_[-1], 'il_diff'].values[0]\n",
    "        ) / 2,\n",
    "        1\n",
    "    )\n",
    "    \n",
    "    df_ejet_30.loc[\n",
    "        range_[0]: pd.to_datetime(range_[1]) - pd.Timedelta(minutes=30),\n",
    "        'il_fix',\n",
    "    ] -= offset_\n",
    "    \n",
    "df_ejet_30 = df_ejet_30.drop(columns='il_diff')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292a314a",
   "metadata": {},
   "source": [
    "Finally, we discretise IE, IL and IU in categories according to their variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fec3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = 6\n",
    "time_steps = 2 * hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d6f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, labels = get_categories(\n",
    "    df_ejet_30['ie_fix'],\n",
    "    window=time_steps,\n",
    "    zero_phase=False,\n",
    ")\n",
    "\n",
    "df_ejet_30['ie_variation'] = np.insert(labels, 0, 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5559e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, labels = get_categories(\n",
    "    df_ejet_30['iu_fix'],\n",
    "    window=time_steps,\n",
    "    zero_phase=False,\n",
    ")\n",
    "\n",
    "df_ejet_30['iu_variation'] = np.insert(labels, 0, 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2696fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, labels = get_categories(\n",
    "    df_ejet_30['il_fix'],\n",
    "    window=time_steps,\n",
    "    zero_phase=False,\n",
    ")\n",
    "\n",
    "df_ejet_30['il_variation'] = np.insert(labels, 0, 0, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495cf567",
   "metadata": {},
   "source": [
    "Here we construct IE, IL and IU moving averages with several rolling windows (3, 6, 12 and 24 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161fd416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n. of periods needed to get 3, 6, 12, 24 hours\n",
    "periods = [2 * per_ for per_ in [3, 6, 12, 24]]\n",
    "\n",
    "for per_ in periods:\n",
    "    # IE moving average\n",
    "    df_ejet_30[f'ie_mav_{per_/2:.0f}h'] = df_ejet_30['ie_fix'].rolling(\n",
    "        window=int(per_)\n",
    "    ).mean().round(1)\n",
    "    \n",
    "    # IU moving average\n",
    "    df_ejet_30[f'iu_mav_{per_/2:.0f}h'] = df_ejet_30['iu_fix'].rolling(\n",
    "        window=int(per_)\n",
    "    ).mean().round(1)\n",
    "    \n",
    "    # IL moving average\n",
    "    df_ejet_30[f'il_mav_{per_/2:.0f}h'] = df_ejet_30['il_fix'].rolling(\n",
    "        window=int(per_)\n",
    "    ).mean().round(1)\n",
    "    \n",
    "df_ejet_30 = df_ejet_30.drop(columns=['ie','il','iu']).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f7b5b",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd84959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_j = df_ejet_30.merge(\n",
    "    df_tid_30_['quality_index'],\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ").merge(\n",
    "    df_hf_30,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ").merge(\n",
    "    df_solar['f_107_adj'],\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ").merge(\n",
    "    df_hp_30,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ").merge(\n",
    "    df_smr_30,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ").merge(\n",
    "    df_l1_30,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ").merge(\n",
    "    df_newell_30,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ").merge(\n",
    "    df_ionosondes_30,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "# Solar data need to be repeated, since they're provided on a daily basis only\n",
    "df_j['f_107_adj'] = df_j['f_107_adj'].ffill()\n",
    "\n",
    "# Solar zenith angle\n",
    "df_j['solar_zenith_angle'] = get_solar_position(\n",
    "    df_j.index, columns='zenith', altitude=0,\n",
    ").round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea6320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_j.reset_index().duplicated('datetime').sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68574402",
   "metadata": {},
   "source": [
    "Construct the actual **target**, a boolean column which is set to 1 whenever a **TID event** is reported **within a 3-hours timeframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5314a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 2 * FORECAST_HOURS_IN_ADVANCE\n",
    "\n",
    "df_j[f'tid_within_{FORECAST_HOURS_IN_ADVANCE}h'] = df_j['quality_index'].rolling(\n",
    "    window=steps+1, min_periods=1\n",
    ").sum().gt(0).shift(\n",
    "    -steps, fill_value=False\n",
    ").replace(\n",
    "    {True: 1, False: 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa600c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class imbalance\n",
    "# 100 * df_j[f'tid_within_{FORECAST_HOURS_IN_ADVANCE}h'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58421050",
   "metadata": {},
   "source": [
    "Construct the **mid-term & mid-accuracy target**, a boolean column which is set to 1 **from 3 to 6 hours before the actual target** is triggered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c74b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_j[\n",
    "#     f'tid_within_{2*FORECAST_HOURS_IN_ADVANCE}h_to_{FORECAST_HOURS_IN_ADVANCE}h'\n",
    "# ] = df_j[f'tid_within_{FORECAST_HOURS_IN_ADVANCE}h'].shift(\n",
    "#     periods=-6, fill_value=0\n",
    "# )\n",
    "\n",
    "# # Avoid overlap in the two targets\n",
    "# df_j[\n",
    "#     f'tid_within_{2*FORECAST_HOURS_IN_ADVANCE}h_to_{FORECAST_HOURS_IN_ADVANCE}h'\n",
    "# ] = np.where(\n",
    "#     df_j[f'tid_within_{FORECAST_HOURS_IN_ADVANCE}h'].eq(1),\n",
    "#     0,\n",
    "#     df_j[f'tid_within_{2*FORECAST_HOURS_IN_ADVANCE}h_to_{FORECAST_HOURS_IN_ADVANCE}h'],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e19221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Class imbalance\n",
    "# 100 * df_j[\n",
    "#     f'tid_within_{2*FORECAST_HOURS_IN_ADVANCE}h_to_{FORECAST_HOURS_IN_ADVANCE}h'\n",
    "# ].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f0139a",
   "metadata": {},
   "source": [
    "### Note to self!\n",
    "\n",
    "if a feature is un-correlated with the target, it doesn't tell you that a **non-linear** model (*e.g.* CatBoost) wouldn't perform well by using this feature\n",
    "\n",
    "Pearson correlation only takes into account *linear* correlation between variables; there might be non-linear (polynomial, logarithmic etc.) relationships between variables. Since the Pearson correlations are low, it seems that the relationships in the dataset (if any) might be non-linear and complex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562966f1",
   "metadata": {},
   "source": [
    "$$\\left( \\frac{\\rm{IE_0 - IE_{3h}}}{\\rm{IE_{3h}}} \\right) ^ {\\rm{HF}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab48c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_j['solar_zenith_angle'].apply(np.real).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e286992a",
   "metadata": {},
   "source": [
    "## Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92748c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_j.drop(\n",
    "    columns=['quality_index'],\n",
    ").to_pickle(\n",
    "    Path(DATA_OUT, 'df_dataset.pickle')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
