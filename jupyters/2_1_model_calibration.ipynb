{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "396d61ce",
   "metadata": {},
   "source": [
    "Classification is a *post hoc* decision layer **on top** of a probabilistic prediction.\n",
    "\n",
    "From this point of view it is obvious that it is essential that, before performing classification, one should have the best possible probabilities to work with. Indeed, for cost-sensitive decisions, having good probabilities is imperative.\n",
    "\n",
    "Standard estimator routines do not necessarily provide this, often returning a ranking/score rather than a probability, and calibration should be performed.\n",
    "\n",
    "Here we shall calibrate a base estimator using the **isotonic regression** and **Venn-ABERS** techniques, and also calculate the results of a strictly-proper scoring rule, namely the Brier score.\n",
    "\n",
    "Some resources:\n",
    "\n",
    "- [What are Brier score and model calibration?](https://neptune.ai/blog/brier-score-and-model-calibration) (Neptune blog)\n",
    "\n",
    "- [How to calibrate a classifier](https://valeman.medium.com/how-to-calibrate-your-classifier-in-an-intelligent-way-a996a2faf718) (Valeriy Manokhin)\n",
    "\n",
    "- About [model uncertainty and conformal prediction](https://blog.dataiku.com/measuring-models-uncertainty-conformal-prediction) (Dataiku blog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ebd374",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    confusion_matrix,\n",
    "    brier_score_loss,\n",
    ")\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from crepes import WrapClassifier\n",
    "from venn_abers import VennAbersCalibrator\n",
    "from var import DATA_OUT, IMAGE_OUT, FORECAST_HOURS_IN_ADVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132cda7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(Path(DATA_OUT, 'df_dataset.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a36726e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = df[\n",
    "    [\n",
    "        'ie_fix',\n",
    "        'ie_variation',\n",
    "        'ie_mav_3h',\n",
    "        'ie_mav_12h',\n",
    "        'iu_fix',\n",
    "        'iu_variation',\n",
    "        'iu_mav_3h',\n",
    "        'iu_mav_12h',\n",
    "        'hf',\n",
    "        'hf_mav_2h',\n",
    "        'f_107_adj',\n",
    "        'hp_30',\n",
    "        'dst',\n",
    "        'solar_zenith_angle',\n",
    "        'newell',\n",
    "        'bz',\n",
    "        'speed',\n",
    "        'rho',\n",
    "        *[col_ for col_ in df.columns if col_.startswith('spectral_contribution_')],\n",
    "        *[col_ for col_ in df.columns if col_.startswith('azimuth_')],\n",
    "        *[col_ for col_ in df.columns if col_.startswith('velocity_')],\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "y = df[f'tid_within_{FORECAST_HOURS_IN_ADVANCE}h'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d066396",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = X.loc['2014':'2020-08'].copy(), y.loc['2014':'2020-08'].copy()\n",
    "X_cal, y_cal = X.loc['2020-09':'2021-06'].copy(), y.loc['2020-09':'2021-06'].copy()\n",
    "X_test, y_test = X.loc['2021-07':].copy(), y.loc['2021-07':].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d05380",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    'ie_variation',\n",
    "    'iu_variation',\n",
    "]\n",
    "\n",
    "static_params = {\n",
    "    \"eval_metric\": \"F1\",\n",
    "    \"random_seed\": 42,\n",
    "    \"auto_class_weights\": \"SqrtBalanced\",\n",
    "    \"cat_features\": cat_features,\n",
    "    \"od_type\": \"Iter\",\n",
    "    \"use_best_model\": True,\n",
    "    \"has_time\": True,\n",
    "    \"od_wait\": 200,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfded08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    loss_function='Logloss',\n",
    "    iterations=1_000,\n",
    "    **static_params,\n",
    ")\n",
    "\n",
    "model = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=(X_test, y_test),\n",
    "    silent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25126102",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b42cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, f, _ = precision_recall_fscore_support(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{f[1].round(3)} F1-score | {p[1].round(3)} precision | {r[1].round(3)} recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b67ca9e",
   "metadata": {},
   "source": [
    "## Evaluation of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = X_test.copy(deep=True)\n",
    "df_eval['true'] = y_test\n",
    "df_eval['pred'] = model.predict(X_test)\n",
    "df_eval['score'] = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682473ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.histogram(\n",
    "#     data_frame=df_eval,\n",
    "#     x=['score'],\n",
    "#     color='true',\n",
    "#     barmode='overlay',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ae796",
   "metadata": {},
   "source": [
    "## Calibration curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1144a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reliability_diagram(prob_pred, prob_true, scores, plot_title=None) -> go.Figure:\n",
    "    \"\"\"Helper function to plot a reliabilitt diagram\"\"\"\n",
    "    fig = px.line(\n",
    "        x=prob_pred,\n",
    "        y=prob_true,\n",
    "        markers=True,\n",
    "    )\n",
    "    fig.update_traces(\n",
    "        selector=dict(type=\"scatter\"),\n",
    "        hovertemplate=\"Mean predicted probability: %{x:.2f}<br>Fraction of positives: %{y:.2f}\",\n",
    "    )\n",
    "\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=0,\n",
    "        y0=0,\n",
    "        x1=1,\n",
    "        y1=1,\n",
    "        line=dict(color=\"red\", width=2, dash=\"dash\"),\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=scores,\n",
    "            yaxis=\"y2\",\n",
    "            opacity=0.3,\n",
    "            showlegend=False,\n",
    "            nbinsx=25,\n",
    "        )\n",
    "    )\n",
    "    fig.update_traces(\n",
    "        selector=dict(type=\"histogram\"),\n",
    "        hovertemplate=\"%{y:,} samples<extra></extra>\",\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Mean predicted probability\",\n",
    "        yaxis_title=\"Fraction of positives\",\n",
    "        yaxis2=dict(title=\"Count of samples\", overlaying=\"y\", side=\"right\"),\n",
    "        title=plot_title,\n",
    "        template=\"simple_white\",\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c6cc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncal_brier = brier_score_loss(\n",
    "    y_test,\n",
    "    df_eval['score'],\n",
    ").round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bdcfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true, prob_pred = calibration_curve(\n",
    "    df_eval['true'],\n",
    "    df_eval['score'],\n",
    "    n_bins=10,\n",
    ")\n",
    "\n",
    "plot_reliability_diagram(\n",
    "    prob_pred=prob_pred,\n",
    "    prob_true=prob_true,\n",
    "    scores=df_eval[\"score\"],\n",
    "    plot_title=f'Uncalibrated model (Brier score: <b>{uncal_brier}</b>)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ceb7ac",
   "metadata": {},
   "source": [
    "## Isotonic calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval['score_iso_cal'] = CalibratedClassifierCV(\n",
    "    estimator=model,\n",
    "    method='isotonic',\n",
    "    cv='prefit',\n",
    ").fit(\n",
    "    X_cal, y_cal,\n",
    ").predict_proba(\n",
    "    X_test\n",
    ")[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ea37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_brier = brier_score_loss(\n",
    "    y_test,\n",
    "    df_eval['score_iso_cal'],\n",
    ").round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b326ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true, prob_pred = calibration_curve(\n",
    "    df_eval['true'],\n",
    "    df_eval['score_iso_cal'],\n",
    "    n_bins=10,\n",
    ")\n",
    "\n",
    "plot_reliability_diagram(\n",
    "    prob_pred=prob_pred,\n",
    "    prob_true=prob_true,\n",
    "    scores=df_eval[\"score_iso_cal\"],\n",
    "    plot_title=f'Calibrated model with isotonic regression (Brier score: <b>{iso_brier}</b>)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc1597e",
   "metadata": {},
   "source": [
    "## (Inductive) Venn-ABERS calibratrion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce364c1",
   "metadata": {},
   "source": [
    "Venn-ABERS predictors perform two isotonic regressions (using the greatest convex minorant of the cumulative sum diagram), one for for class 0 leading to probabilities $p_0$, and one for class 1 leading to probabilities $p_1$.\n",
    "\n",
    "$p_0$ and $p_1$ form an interval within which the correct probability is deemed to be located. A single-valued probability can be obtained by combining these results, for example via\n",
    "\n",
    "$$p \\equiv \\frac{p_1}{1 âˆ’ p_0 + p_1}$$\n",
    "\n",
    "Note that Inductive Venn-ABERS (IVA) needs a **disjoint hold-out calibration dataset** (`X_cal`, `y_cal`) extracted from the training data\n",
    "\n",
    "What is a [Venn predictor](https://link.springer.com/chapter/10.1007/978-3-031-06649-8_6)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iva_cal = VennAbersCalibrator(inductive=True)\n",
    "\n",
    "score_iva_cal, p0_p1 = iva_cal.predict_proba(\n",
    "    p_cal=model.predict_proba(X_cal),\n",
    "    y_cal=y_cal.values,\n",
    "    p_test=model.predict_proba(X_test),\n",
    "    p0_p1_output=True,\n",
    ")\n",
    "\n",
    "df_eval['score_iva_cal'] = score_iva_cal[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa84ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('iva_cal_model.pkl', 'wb') as f:\n",
    "    pickle.dump(iva_cal, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5ada0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('iva_cal_model.pkl', 'rb') as f:\n",
    "    iva_cal_ = pickle.load(f)\n",
    "    \n",
    "score_iva_cal_, p0_p1 = iva_cal_.predict_proba(\n",
    "    p_cal=model.predict_proba(X_cal),\n",
    "    y_cal=y_cal.values,\n",
    "    p_test=model.predict_proba(X_test),\n",
    "    p0_p1_output=True,\n",
    ")\n",
    "\n",
    "df_eval['score_iva_cal_'] = score_iva_cal_[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b390ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "iva_brier = brier_score_loss(\n",
    "    y_test,\n",
    "    df_eval['score_iva_cal'],\n",
    ").round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caa337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iva_brier_ = brier_score_loss(\n",
    "    y_test,\n",
    "    df_eval['score_iva_cal_'],\n",
    ").round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b2a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true, prob_pred = calibration_curve(\n",
    "    df_eval['true'],\n",
    "    df_eval['score_iva_cal'],\n",
    "    n_bins=10,\n",
    ")\n",
    "\n",
    "plot_reliability_diagram(\n",
    "    prob_pred=prob_pred,\n",
    "    prob_true=prob_true,\n",
    "    scores=df_eval[\"score_iva_cal\"],\n",
    "    plot_title=f'Calibrated model with Venn-ABERS (Brier score: <b>{iva_brier}</b>)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.line(\n",
    "#     y_test - df_eval['score_iva_cal']\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff6c25e",
   "metadata": {},
   "source": [
    "## Prediction interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval['score_iva_cal_up'] = p0_p1[:,1]\n",
    "df_eval['score_iva_cal_lw'] = p0_p1[:,0]\n",
    "df_eval['width'] = df_eval['score_iva_cal_up'] - df_eval['score_iva_cal_lw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e63da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = df_eval.loc['2022-03'].copy().sort_values(by=['score_iva_cal']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f682bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = preds.index.tolist() + preds.index.tolist()[::-1]\n",
    "# y = preds['score_iva_cal_up'].tolist() + preds['score_iva_cal_lw'].tolist()[::-1]\n",
    "\n",
    "# fig = go.Figure()\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter(\n",
    "#         x=x,\n",
    "#         y=y,\n",
    "#         fill='tozeroy',\n",
    "#         fillcolor='rgba(0,100,80,0.4)',\n",
    "#         line=dict(color='rgba(0,0,0,0.2)'),\n",
    "#         name='Prediction interval',\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# fig.add_scatter(\n",
    "#     x=preds.index,\n",
    "#     y=preds['width'],\n",
    "#     mode='lines',\n",
    "#     name=\"Width\",\n",
    "#     line=dict(width=1.2, color=\"firebrick\"),\n",
    "# )\n",
    "\n",
    "# fig.update_layout(\n",
    "#     xaxis=dict(tickvals=[], ticktext=[], title=''),\n",
    "#     yaxis=dict(title=\"Estimated probability\"),\n",
    "#     template='plotly_white',\n",
    "#     legend_title='',\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9795e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_period_beg = '2022-03-09'\n",
    "time_period_end = '2022-03-17'\n",
    "n_labels = 5\n",
    "label_every = len(preds.index)//n_labels\n",
    "\n",
    "preds = df_eval.loc[time_period_beg:time_period_end].copy().reset_index(drop=True)\n",
    "x = preds.index.tolist() + preds.index.tolist()[::-1]\n",
    "x_ts = (\n",
    "    df_eval.loc[time_period_beg:time_period_end].index.to_list() +\n",
    "    df_eval.loc[time_period_beg:time_period_end].index.to_list()[::-1]\n",
    ")\n",
    "y = preds['score_iva_cal_up'].tolist() + preds['score_iva_cal_lw'].tolist()[::-1]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        fill='tozeroy',\n",
    "        fillcolor='rgba(0,100,80,0.4)',\n",
    "        line=dict(color='rgba(0,0,0,0.2)'),\n",
    "        name='Pred. interval',\n",
    "        hovertext=[f\"{date}<br><b>{prob:.2f}</b>\" for date, prob in zip(x_ts, y)],\n",
    "        hoverinfo='text',\n",
    "    )\n",
    ")\n",
    "fig.add_scatter(\n",
    "    x=preds.index,\n",
    "    y=preds['width'],\n",
    "    mode='lines',\n",
    "    name=\"Pred. int. width\",\n",
    "    line=dict(width=1.2, color=\"firebrick\"),\n",
    "    hovertext=[f\"{date}<br><b>{w:.2f}</b>\" for date, w in zip(x_ts, preds['width'])],\n",
    "    hoverinfo='text',\n",
    ")\n",
    "fig.update_layout(\n",
    "    height=550,\n",
    "    width=800,\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=preds.index[::label_every],\n",
    "        ticktext=[\n",
    "            val_.strftime('%d-%m, %H:%M') for val_ in\n",
    "            df_eval.loc[time_period_beg:time_period_end].index.tolist()[::label_every]\n",
    "        ],\n",
    "        title='',\n",
    "    ),\n",
    "    title=dict(text=\"Estimated probability of LSTID occurrence, 9 to 17 March 2022\"),\n",
    "    template='simple_white',\n",
    "    legend_title='',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c94579",
   "metadata": {},
   "source": [
    "## crepes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a9085",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_crep = WrapClassifier(model).calibrate(X_cal, y_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d7f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_crep.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4844b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_crep.predict_p(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_crep.predict_set(X_test, confidence=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2404afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_crep.evaluate(X_test, y_test, confidence=0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb0afa",
   "metadata": {},
   "source": [
    "- \"error\" is the  fraction of prediction sets not containing the true class label\n",
    "- \"avg_c\" is the average no. of predicted class labels\n",
    "- \"one_c\" is the fraction of singleton prediction sets\n",
    "- \"empty\" is the fraction of empty prediction sets\n",
    "- \"time_fit\" is the time taken to fit the conformal classifier\n",
    "- \"time_evaluate\" is the time taken for the evaluation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
